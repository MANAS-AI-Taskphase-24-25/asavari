{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d1ac22-48ab-4a56-8e21-08d9c0264123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccec7701-4cfb-493d-80a8-40656e0e0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate, reg_lambda):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg_lambda = reg_lambda\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, z):\n",
    "        return z * (1 - z)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_scores = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        logprobs = -np.log(y_pred[range(m), y_true])\n",
    "        data_loss = np.sum(logprobs) / m\n",
    "\n",
    "        # Add regularization term to loss\n",
    "        data_loss += (self.reg_lambda / 2) * (np.sum(np.square(self.W1)) + np.sum(np.square(self.W2)))\n",
    "        return data_loss\n",
    "\n",
    "    def backward_propagation(self, X, y_true, y_pred):\n",
    "        m = X.shape[0]\n",
    "\n",
    "        delta3 = y_pred\n",
    "        delta3[range(m), y_true] -= 1\n",
    "        dW2 = (np.dot(self.a1.T, delta3) + self.reg_lambda * self.W2) / m\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True) / m\n",
    "\n",
    "        delta2 = np.dot(delta3, self.W2.T) * self.sigmoid_derivative(self.a1)\n",
    "        dW1 = (np.dot(X.T, delta2) + self.reg_lambda * self.W1) / m\n",
    "        db1 = np.sum(delta2, axis=0) / m\n",
    "\n",
    "        # Update weights and biases using gradient descent\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=500):\n",
    "        loss_history = []\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward_propagation(X_train)\n",
    "            loss = self.compute_loss(y_train, y_pred)\n",
    "            loss_history.append(loss)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "            self.backward_propagation(X_train, y_train, y_pred)\n",
    "        \n",
    "        return loss_history\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward_propagation(X)\n",
    "        return np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499c5ad5-3375-4d94-bea9-93d5ea9373a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading the dataset\n",
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_names = os.listdir(data_dir)\n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            file_path = os.path.join(class_dir, file_name)\n",
    "            image = Image.open(file_path).convert('L')\n",
    "            image = image.resize((28, 28))\n",
    "            image_array = np.array(image).flatten()  \n",
    "            X.append(image_array)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81ce218a-1f3b-458c-8505-2b2e3b975d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for splitting the dataset into training and validation sets\n",
    "def train_test_split(X, y, test_size=0.2):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    split_idx = int(X.shape[0] * (1 - test_size))\n",
    "    X_train, X_test = X[indices[:split_idx]], X[indices[split_idx:]]\n",
    "    y_train, y_test = y[indices[:split_idx]], y[indices[split_idx:]]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc0a28a-d4fd-40f5-ac50-b36e96598ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11491/2737512052.py:12: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  image_array = np.array(image).flatten()\n"
     ]
    }
   ],
   "source": [
    "X_train_full, y_train_full, class_names = load_data('/home/asavari/Downloads/Train')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "# Iinitialization and training of nn\n",
    "input_size = 28 * 28\n",
    "hidden_size = 128\n",
    "output_size = len(class_names)\n",
    "learning_rate = 0.01\n",
    "reg_lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ca0f0-9229-4082-9a20-ebfa65d3fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.6583791922410123\n",
      "Epoch 100, Loss: 0.8495510344275822\n",
      "Epoch 200, Loss: 0.49872256260648784\n",
      "Epoch 300, Loss: 0.37746591149886144\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(input_size=input_size,\n",
    "                   hidden_size=hidden_size,\n",
    "                   output_size=output_size,\n",
    "                   learning_rate=learning_rate,\n",
    "                   reg_lambda=reg_lambda)\n",
    "\n",
    "loss=nn.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19c939-70bf-445e-9f94-c68b31233c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = nn.predict(X_val)\n",
    "accuracy_val = np.mean(y_val_pred == y_val)\n",
    "print(f'Validation Accuracy: {accuracy_val*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2f152-0cfe-4cfe-b10d-4c6197b77ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_full, y_test_full, _ = load_data('/home/asavari/Downloads/Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086167b4-4a92-41da-9bd4-01a8978e4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = nn.predict(X_test_full)\n",
    "accuracy_pred = np.mean(y_test_pred == y_test_full)\n",
    "print(f'Test Accuracy: {accuracy_pred*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec72d43-e46b-4a72-93c0-124b072d88da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting random predictions on test data\n",
    "fig, axes = plt.subplots(3, 3)\n",
    "fig.suptitle('Random Predictions on Test Data')\n",
    "random_indices = np.random.choice(len(X_test_full), size=9, replace=False)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        idx = random_indices[i * 3 + j]\n",
    "        axes[i][j].imshow(X_test_full[idx].reshape(28, 28), cmap='gray')\n",
    "        axes[i][j].set_title(f'Predicted: {class_names[y_test_pred[idx]]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dfc2e5-145c-4c72-9234-742267f02214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
